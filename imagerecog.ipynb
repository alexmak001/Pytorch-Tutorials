{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('PytorchVS': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f9de795ee7e4b84a37ca8c2e2c979dd3cfd75580105ed1b581816aba772ecc54"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np \n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training dataset\n",
    "dataset = MNIST(root='data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x1B9BADBD9A0>, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring data\n",
    "image, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1B9B99B6790>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x1B9C3E06970>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5klEQVR4nGNgoD9gRGJr+aSevsAw4Rc2demf/v379++fE1ZDhF78+/fv3793blhlM778e/Dv379e7A44/+/Sv3//lLBLhpz79+/fP00cbpe4+O/fv9VwLguyXLSeDgMDw1Fs2jSu/fr3D8VOJoSkpiLEmAKsNuZ9+/cPp52TbgswsEzmw+FYBgYGxoZ/t+VxSbL/+3dNBpdk179/JehiwhujGBgYGBgkP2AJviX/rturMBhHnvv3r5sDXdLy6L9/97Z8/Pfv71VuTLt6Mv/9+/fv3783yIIwf5aw8zAYRDJ8xB7TdAQABFdhZWAfWxoAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dataset[10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert array of images to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root=\"data/\", train=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor, label = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "\n",
    "def split_indicies(n, val_pct):\n",
    "    # size of validation set\n",
    "    n_val = int(val_pct*n)\n",
    "\n",
    "    #create random permutations of 0 to n-1\n",
    "    idxs =np.random.permutation(n)\n",
    "\n",
    "    # return first n_val indicies for validation set\n",
    "    return idxs[n_val:], idxs[:n_val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% validation set\n",
    "train_indicies, val_indicies = split_indicies(len(dataset),0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "48000 12000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_indicies),len(val_indicies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pytorch data loaders for each of these using a SubsetRandomSampler: randomly samples a given list of indicies and creates batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "\n",
    "#training sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indicies)\n",
    "train_loader = DataLoader(dataset, batch_size, sampler=train_sampler)\n",
    "\n",
    "#validation sampler and data loader\n",
    "val_sampler = SubsetRandomSampler(val_indicies)\n",
    "val_loader = DataLoader(dataset, batch_size, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistis regressiona model: x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 784])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "model.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model.bias.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-b0fccba1ff71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PytorchVS\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2800x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "# pass our image into the initiated weights\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an erro because the weights are 28*28,  but the training data is 1*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinstModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1,784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "\n",
    "model = MinstModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "outputs.shape :  torch.Size([100, 10])\n",
      "Sample outputs :\n",
      " tensor([[-0.2654, -0.2348, -0.0676,  0.1688, -0.1232,  0.0370, -0.0961, -0.0806,\n",
      "          0.0180, -0.0199],\n",
      "        [-0.3245, -0.1504, -0.0913,  0.4855, -0.0799, -0.3737, -0.1653, -0.0829,\n",
      "          0.1533, -0.0501]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    break\n",
    "\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F \n",
    "# includes the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0813, 0.0839, 0.0991, 0.1256, 0.0938, 0.1101, 0.0964, 0.0979, 0.1080,\n",
       "         0.1040],\n",
       "        [0.0752, 0.0895, 0.0949, 0.1690, 0.0960, 0.0716, 0.0881, 0.0957, 0.1212,\n",
       "         0.0989],\n",
       "        [0.0815, 0.0893, 0.1095, 0.1082, 0.1003, 0.1006, 0.0816, 0.1163, 0.1024,\n",
       "         0.1103],\n",
       "        [0.0601, 0.1073, 0.0861, 0.1729, 0.0728, 0.1118, 0.0797, 0.1204, 0.1067,\n",
       "         0.0821],\n",
       "        [0.0838, 0.1098, 0.1134, 0.1560, 0.0672, 0.1070, 0.0895, 0.1168, 0.0794,\n",
       "         0.0772],\n",
       "        [0.0871, 0.1397, 0.0827, 0.1136, 0.0738, 0.0951, 0.1021, 0.0974, 0.1237,\n",
       "         0.0847],\n",
       "        [0.0945, 0.1286, 0.0924, 0.1036, 0.0927, 0.1121, 0.0988, 0.0961, 0.0982,\n",
       "         0.0829],\n",
       "        [0.0651, 0.0803, 0.0812, 0.1581, 0.0824, 0.1227, 0.0874, 0.1076, 0.1020,\n",
       "         0.1132],\n",
       "        [0.0715, 0.0948, 0.1129, 0.1170, 0.0894, 0.0944, 0.0734, 0.1260, 0.1024,\n",
       "         0.1182],\n",
       "        [0.0827, 0.0848, 0.1027, 0.1407, 0.0996, 0.0973, 0.1001, 0.1071, 0.0758,\n",
       "         0.1092]], grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "probs = F.softmax(outputs, dim=1)\n",
    "probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability for each number, so need to calculate the highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([3, 3, 7, 3, 3, 1, 1, 3, 7, 3, 3, 3, 7, 3, 8, 3, 7, 7, 3, 3, 3, 8, 1, 3,\n        8, 3, 1, 3, 3, 3, 3, 7, 3, 7, 7, 3, 3, 7, 7, 8, 7, 7, 3, 9, 3, 3, 7, 3,\n        3, 3, 3, 7, 3, 7, 8, 3, 1, 7, 1, 3, 8, 7, 3, 3, 7, 8, 7, 9, 3, 3, 4, 8,\n        3, 7, 3, 7, 3, 7, 3, 7, 7, 2, 7, 3, 3, 7, 8, 7, 1, 7, 3, 7, 3, 3, 1, 7,\n        7, 7, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6, 2, 1, 8, 5, 7, 7, 3, 1, 1, 1, 8, 9, 2, 2, 8, 6, 3, 9, 2, 3, 4, 7, 5,\n",
       "        0, 6, 7, 6, 2, 3, 9, 8, 2, 3, 7, 8, 3, 0, 3, 2, 0, 6, 2, 7, 3, 7, 0, 3,\n",
       "        4, 2, 6, 1, 3, 3, 7, 9, 9, 0, 7, 1, 4, 7, 3, 8, 3, 3, 5, 1, 6, 0, 3, 9,\n",
       "        6, 0, 6, 1, 9, 3, 2, 3, 6, 3, 7, 4, 5, 5, 3, 1, 7, 9, 4, 1, 9, 2, 9, 9,\n",
       "        5, 6, 2, 9])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(l1, l2):\n",
    "    return torch.sum(l1 == l2).item()/len(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "accuracy(preds,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross entropy as a loss function\n",
    "# picks the label prediction value and natural logs it\n",
    "# it is differentiable, and allows for small steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(2.2974, grad_fn=<NllLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "loss = loss_fn(outputs, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the loss for each iteration of a batch\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "\n",
    "    # calculate loss\n",
    "    preds = model(xb)\n",
    "    loss = loss_func(preds, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        #compute gradients\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        opt.step()\n",
    "        # reset gradients\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        # computer the metric\n",
    "        metric_result = metric(preds, yb)\n",
    "    \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the overall loss for the validation set\n",
    "\n",
    "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
    "\n",
    "    # do not need to keep track of gradients\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # pass each batch through the model\n",
    "        results = [loss_batch(model,loss_fn, xb, yb, metric=metric) for xb,yb in valid_dl]\n",
    "\n",
    "        # separate losses, counts and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "\n",
    "        # total size of the dataset\n",
    "        total = np.sum(nums)\n",
    "\n",
    "        # average loss across teh batches\n",
    "        avg_loss = np.sum(np.multiply(losses, nums))/ total\n",
    "\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "\n",
    "            # average of metric across the batches\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums))/total\n",
    "    \n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs,labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2.3440155565738676, 12000, 0.07591666666666666)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "evaluate(model, loss_fn, val_loader, metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_fn, opt, train_dl, valid_dl, metric=None):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Training\n",
    "        for xb, yb in train_dl:\n",
    "            loss, _, _ = loss_batch(model,loss_fn, xb, yb, opt)\n",
    "\n",
    "        result = evaluate(model,loss_fn, valid_dl,metric)\n",
    "        val_loss, total, val_metric = result\n",
    "\n",
    "        # Evaluating\n",
    "        if metric is None:\n",
    "            print(\"Epoch: {0}/{1}, Loss: {2}\".format(epoch+1,epochs,val_loss))\n",
    "        else:\n",
    "            print(\"Epoch: {0}/{1}, Loss: {2}, {3}:{4}\".format(epoch+1,epochs, val_loss,metric.__name__,val_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can easily reset model if needed\n",
    "model = MinstModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1/10, Loss: 1.5449748486280441, accuracy:0.74575\n",
      "Epoch: 2/10, Loss: 1.5221473147471747, accuracy:0.7499166666666667\n",
      "Epoch: 3/10, Loss: 1.5000946581363679, accuracy:0.7539166666666667\n",
      "Epoch: 4/10, Loss: 1.4787936190764108, accuracy:0.75725\n",
      "Epoch: 5/10, Loss: 1.4582076092561087, accuracy:0.7608333333333334\n",
      "Epoch: 6/10, Loss: 1.4383109261592228, accuracy:0.7629166666666667\n",
      "Epoch: 7/10, Loss: 1.4190746714671454, accuracy:0.7649166666666667\n",
      "Epoch: 8/10, Loss: 1.4004718820254007, accuracy:0.7671666666666667\n",
      "Epoch: 9/10, Loss: 1.3824775705734889, accuracy:0.7690833333333333\n",
      "Epoch: 10/10, Loss: 1.3650664915641149, accuracy:0.7713333333333333\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "fit(10, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "test_dataset[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img,model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "img1, label1 = test_dataset[100]\n",
    "label1, predict_image(img1,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test loss, total, test accracy\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.338359444141388, 10000, 0.7901)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "# 79% accuracy\n",
    "test_loader = DataLoader(test_dataset, batch_size=200)\n",
    "print(\"test loss, total, test accracy\")\n",
    "evaluate(model, loss_fn, test_loader, metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mnist-logistic.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0228, -0.0098, -0.0198,  ..., -0.0069, -0.0083, -0.0222],\n",
       "                      [ 0.0202, -0.0226, -0.0082,  ..., -0.0196,  0.0058,  0.0074],\n",
       "                      [-0.0344,  0.0342,  0.0307,  ..., -0.0323, -0.0241, -0.0269],\n",
       "                      ...,\n",
       "                      [-0.0068, -0.0096, -0.0206,  ...,  0.0143,  0.0184,  0.0094],\n",
       "                      [-0.0229, -0.0052, -0.0298,  ...,  0.0143, -0.0082,  0.0273],\n",
       "                      [-0.0246, -0.0205,  0.0022,  ...,  0.0022, -0.0207,  0.0028]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0332,  0.0304, -0.0080,  0.0249, -0.0105, -0.0205, -0.0211,  0.0011,\n",
       "                       0.0066, -0.0232]))])"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0228, -0.0098, -0.0198,  ..., -0.0069, -0.0083, -0.0222],\n",
       "                      [ 0.0202, -0.0226, -0.0082,  ..., -0.0196,  0.0058,  0.0074],\n",
       "                      [-0.0344,  0.0342,  0.0307,  ..., -0.0323, -0.0241, -0.0269],\n",
       "                      ...,\n",
       "                      [-0.0068, -0.0096, -0.0206,  ...,  0.0143,  0.0184,  0.0094],\n",
       "                      [-0.0229, -0.0052, -0.0298,  ...,  0.0143, -0.0082,  0.0273],\n",
       "                      [-0.0246, -0.0205,  0.0022,  ...,  0.0022, -0.0207,  0.0028]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0332,  0.0304, -0.0080,  0.0249, -0.0105, -0.0205, -0.0211,  0.0011,\n",
       "                       0.0066, -0.0232]))])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "model2 = MinstModel()\n",
    "model2.load_state_dict(torch.load(\"mnist-logistic.pth\"))\n",
    "model2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test loss, total, test accracy\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.338359444141388, 10000, 0.7901)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "# same exact values\n",
    "print(\"test loss, total, test accracy\")\n",
    "evaluate(model2, loss_fn, test_loader, metric=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}